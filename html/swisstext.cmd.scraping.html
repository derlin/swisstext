
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Scraping commandline tool &#8212; SwissText  documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Command line scraping tools" href="swisstext.cmd.scraping.tools.html" />
    <link rel="prev" title="MongoDB Collections definitions" href="swisstext.mongo.abstract.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="swisstext.cmd.scraping.tools.html" title="Command line scraping tools"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="swisstext.mongo.abstract.html" title="MongoDB Collections definitions"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">SwissText  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="apireference.html" accesskey="U">API Reference</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-swisstext.cmd.scraping">
<span id="scraping-commandline-tool"></span><h1>Scraping commandline tool<a class="headerlink" href="#module-swisstext.cmd.scraping" title="Permalink to this headline">¶</a></h1>
<p>The scraping module is able to scrape the web in order to find new Swiss German sentences.</p>
<span class="target" id="module-swisstext.cmd.scraping.commandline"></span><p>This module contains the commandline interface for the scraper.</p>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p>Use the <cite>–help</cite> option to discover the capabilities and options of the tool.</p>
<div class="admonition-todo admonition" id="index-0">
<p class="first admonition-title">Todo</p>
<ul class="last simple">
<li>Also exit cleanly when only one worker runs in the main thread</li>
</ul>
</div>
<dl class="function">
<dt id="swisstext.cmd.scraping.commandline.enqueue">
<code class="descclassname">swisstext.cmd.scraping.commandline.</code><code class="descname">enqueue</code><span class="sig-paren">(</span><em>url</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/commandline.html#enqueue"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.commandline.enqueue" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-swisstext.cmd.scraping.interfaces">
<span id="tool-interfaces"></span><h2>Tool interfaces<a class="headerlink" href="#module-swisstext.cmd.scraping.interfaces" title="Permalink to this headline">¶</a></h2>
<p>This module defines interfaces for each tool or decision maker used in the scraping process.
This makes it easy to test new ways or to tune one aspect of the scraper while keeping most of the code unchanged.</p>
<p>See the <a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools" title="swisstext.cmd.scraping.tools"><code class="xref py py-mod docutils literal notranslate"><span class="pre">swisstext.cmd.scraping.tools</span></code></a> module for implementations.</p>
<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ICrawler</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ICrawler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>[ABSTRACT] This tool is in charge of crawling a page. More specifically, it should be able to:
1. extract the text of the page (stripped of any HTML or other structural clue),
2. extract links pointing to other pages</p>
<dl class="exception">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.CrawlError">
<em class="property">exception </em><code class="descname">CrawlError</code><span class="sig-paren">(</span><em>message: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ICrawler.CrawlError"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlError" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#Exception" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></a></p>
<p>This wrapper should be used for any exception that arise during scraping.</p>
</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults">
<em class="property">class </em><code class="descname">CrawlResults</code><span class="sig-paren">(</span><em>text: str, links: List[str]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ICrawler.CrawlResults"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Holds the results of a page crawl.</p>
<dl class="attribute">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults.links">
<code class="descname">links</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults.links" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of interesting links found in the page. By interesting, we mean:
* no duplicates
* different from the current page URL (no anchors !)
* if possible, no link pointing to unparseable resources (zip files, images, etc.)
The method <code class="xref py py-meth docutils literal notranslate"><span class="pre">swisstext.cmd.scraping.link_utils.filter_links()</span></code> is available to do the filtering.</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults.text">
<code class="descname">text</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults.text" title="Permalink to this definition">¶</a></dt>
<dd><p>the clean text found in the page, free of any structural marker such as HTML tags, etc.</p>
</dd></dl>

</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.crawl">
<code class="descname">crawl</code><span class="sig-paren">(</span><em>url: str</em><span class="sig-paren">)</span> &#x2192; swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ICrawler.crawl"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.crawl" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT]
Should crawl the page and extract the text and the links into a <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults" title="swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults"><code class="xref py py-class docutils literal notranslate"><span class="pre">ICrawler.CrawlResults</span></code></a> instance.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.IDecider">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">IDecider</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#IDecider"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.IDecider" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A decider should implement the logic behind whether or not a URL is considered interesting/should be crawled.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.IDecider.should_children_be_crawled">
<code class="descname">should_children_be_crawled</code><span class="sig-paren">(</span><em>page: swisstext.cmd.scraping.data.Page</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#IDecider.should_children_be_crawled"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.IDecider.should_children_be_crawled" title="Permalink to this definition">¶</a></dt>
<dd><p>Decide if the links found on a page should be scraped on this run. Returns true by default.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.IDecider.should_page_be_crawled">
<code class="descname">should_page_be_crawled</code><span class="sig-paren">(</span><em>page: swisstext.cmd.scraping.data.Page</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#IDecider.should_page_be_crawled"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.IDecider.should_page_be_crawled" title="Permalink to this definition">¶</a></dt>
<dd><p>Decide if a page should be scraped on this run. By default, it returns always true, but we could devise other
rules based on the last crawl, etc.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.IDecider.should_url_be_blacklisted">
<code class="descname">should_url_be_blacklisted</code><span class="sig-paren">(</span><em>page: swisstext.cmd.scraping.data.Page</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#IDecider.should_url_be_blacklisted"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.IDecider.should_url_be_blacklisted" title="Permalink to this definition">¶</a></dt>
<dd><p>Decide if a URL/page is blacklisted. The default implementation returns true if the URL has never been
visited before <em>and</em> contains no Swiss German sentence. The <em>new</em> criteria is important to avoid blacklisting
a page that changed over time, but contained once interesting sentences (and thus might be referenced in
the persistence layer).</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISaver">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISaver</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>[ABSTRACT] The saver is responsible for persisting everything somewhere, such as a database, a file or the console.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.blacklist_url">
<code class="descname">blacklist_url</code><span class="sig-paren">(</span><em>url: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.blacklist_url"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.blacklist_url" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Add the <cite>url</cite> to a blacklist.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.get_page">
<code class="descname">get_page</code><span class="sig-paren">(</span><em>url: str</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.get_page"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.get_page" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a page. The simplest implementation is just <code class="docutils literal notranslate"><span class="pre">return</span> <span class="pre">Page(url)</span></code>.
If the subclass uses a data store, it should also populate the other page attributes (e.g. the score
information) so that the :py:class::<cite>IDecider</cite> can make clever decisions.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.is_url_blacklisted">
<code class="descname">is_url_blacklisted</code><span class="sig-paren">(</span><em>url: str</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.is_url_blacklisted"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.is_url_blacklisted" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Tells if the given <cite>url</cite> is part of the blacklist. This is called at the beginning,
to avoid scraping pages unnecessarily.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.save_page">
<code class="descname">save_page</code><span class="sig-paren">(</span><em>page: swisstext.cmd.scraping.data.Page</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.save_page"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.save_page" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Persist a page.
This is called after the scraping, so all page’s attributes are set, including the
list of new :py:class::<cite>~swisstext.cmd.scraping.data.Sentence</cite> found.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.save_seed">
<code class="descname">save_seed</code><span class="sig-paren">(</span><em>seed: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.save_seed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.save_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Persist a seed (usually generated by the :py:class::<cite>ISeedGenerator</cite>).</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.save_seeds">
<code class="descname">save_seeds</code><span class="sig-paren">(</span><em>seeds: List[str]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.save_seeds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.save_seeds" title="Permalink to this definition">¶</a></dt>
<dd><p>Persist multiple seeds (see <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ISaver.save_seed" title="swisstext.cmd.scraping.interfaces.ISaver.save_seed"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_seed()</span></code></a>).</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.sentence_exists">
<code class="descname">sentence_exists</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.sentence_exists"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.sentence_exists" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Tells if the given Swiss German <cite>sentence</cite> already exists.
Only new sentences will be added to the page’s <a class="reference internal" href="#swisstext.cmd.scraping.data.Page.new_sg" title="swisstext.cmd.scraping.data.Page.new_sg"><code class="xref py py-attr docutils literal notranslate"><span class="pre">new_sg</span></code></a> attribute.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISeedCreator">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISeedCreator</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISeedCreator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISeedCreator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>[ABSTRACT] A seed creator should generate seeds, i.e. search queries, out of Swiss German sentences.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISeedCreator.generate_seeds">
<code class="descname">generate_seeds</code><span class="sig-paren">(</span><em>sentences: List[str], max=10, stopwords: List[str] = []</em><span class="sig-paren">)</span> &#x2192; List[str]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISeedCreator.generate_seeds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISeedCreator.generate_seeds" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Should generate interesting seeds.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>sentences</strong> – the sentences</li>
<li><strong>max</strong> – maximum number of seeds to return</li>
<li><strong>stopwords</strong> – an optional list of words to exclude from generated seeds</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">a list of seeds</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISentenceFilter">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISentenceFilter</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISentenceFilter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISentenceFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A sentence filter should be able to tell if a given sentence is well-formed (i.e. valid) or not.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISentenceFilter.filter">
<code class="descname">filter</code><span class="sig-paren">(</span><em>sentences: List[str]</em><span class="sig-paren">)</span> &#x2192; List[str]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISentenceFilter.filter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISentenceFilter.filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter a list of sentences by calling <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ISentenceFilter.is_valid" title="swisstext.cmd.scraping.interfaces.ISentenceFilter.is_valid"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ISentenceFilter.is_valid()</span></code></a> on each element.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISentenceFilter.is_valid">
<code class="descname">is_valid</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISentenceFilter.is_valid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISentenceFilter.is_valid" title="Permalink to this definition">¶</a></dt>
<dd><p>This should be overriden. The default implementation just returns true.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISgDetector">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISgDetector</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISgDetector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISgDetector" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>[ABSTRACT] An SG Detector is a Language Identifier supporting Swiss German.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISgDetector.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>sentences: List[str]</em><span class="sig-paren">)</span> &#x2192; List[float]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISgDetector.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISgDetector.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Predict the Swiss German probability (between 0 and 1) of a list of sentences.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISgDetector.predict_one">
<code class="descname">predict_one</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISgDetector.predict_one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISgDetector.predict_one" title="Permalink to this definition">¶</a></dt>
<dd><p>Call <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ISgDetector.predict" title="swisstext.cmd.scraping.interfaces.ISgDetector.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> with one sentence.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISplitter">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISplitter</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISplitter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISplitter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A splitter should take a [long] text (extracted from a web page) and split it into well-formed sentences.
The default implementation just splits on the newline character.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISplitter.split">
<code class="descname">split</code><span class="sig-paren">(</span><em>text: str</em><span class="sig-paren">)</span> &#x2192; List[str]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISplitter.split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISplitter.split" title="Permalink to this definition">¶</a></dt>
<dd><p>This should be overriden. The default implementation just splits on newlines.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISplitter.split_all">
<code class="descname">split_all</code><span class="sig-paren">(</span><em>texts: List[str]</em><span class="sig-paren">)</span> &#x2192; List[str]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISplitter.split_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISplitter.split_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a list of texts and returns a list of sentences (see <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ISplitter.split" title="swisstext.cmd.scraping.interfaces.ISplitter.split"><code class="xref py py-meth docutils literal notranslate"><span class="pre">split()</span></code></a>).</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="tool-implementations">
<h2>Tool implementations<a class="headerlink" href="#tool-implementations" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="swisstext.cmd.scraping.tools.html">Command line scraping tools</a><ul>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.basic_decider">Deciders</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.basic_seed_creator">Seed Creators</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.bs_crawler">Crawlers</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.console_saver">Savers</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.pattern_sentence_filter">Sentence Filters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#how-it-works">How it works</a></li>
<li class="toctree-l3"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#rule-syntax">Rule syntax</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.punkt_splitter">Splitters</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.swigspot_langid">Language Detectors</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="module-swisstext.cmd.scraping.config">
<span id="configuration"></span><h2>Configuration<a class="headerlink" href="#module-swisstext.cmd.scraping.config" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="swisstext.cmd.scraping.config.Config">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.config.</code><code class="descname">Config</code><span class="sig-paren">(</span><em>config: Union[str</em>, <em>dict</em>, <em>io.IOBase] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/config.html#Config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.config.Config" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="swisstext.cmd.html#swisstext.cmd.base_config.BaseConfig" title="swisstext.cmd.base_config.BaseConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">swisstext.cmd.base_config.BaseConfig</span></code></a></p>
<p>The default configuration file for the scraping pipeline is defined in <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code>. This is the best way
to understand what options are available.</p>
<dl class="class">
<dt id="swisstext.cmd.scraping.config.Config.Options">
<em class="property">class </em><code class="descname">Options</code><span class="sig-paren">(</span><em>num_workers=1</em>, <em>min_proba=0.85</em>, <em>crawl_depth=2</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/config.html#Config.Options"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.config.Config.Options" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Holds the general options for the scraping pipeline.</p>
<dl class="attribute">
<dt id="swisstext.cmd.scraping.config.Config.Options.crawl_depth">
<code class="descname">crawl_depth</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.config.Config.Options.crawl_depth" title="Permalink to this definition">¶</a></dt>
<dd><p>maximum depth of the crawl, inclusive.</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.config.Config.Options.min_proba">
<code class="descname">min_proba</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.config.Config.Options.min_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>minimum Swiss German probability to keep a sentence</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.config.Config.Options.num_workers">
<code class="descname">num_workers</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.config.Config.Options.num_workers" title="Permalink to this definition">¶</a></dt>
<dd><p>maximum number of threads to use</p>
</dd></dl>

</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.config.Config.create_pipeline">
<code class="descname">create_pipeline</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; swisstext.cmd.scraping.pipeline.Pipeline<a class="reference internal" href="_modules/swisstext/cmd/scraping/config.html#Config.create_pipeline"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.config.Config.create_pipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate a pipeline from the YAML configuration.</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.config.Config.interfaces_package">
<code class="descname">interfaces_package</code><a class="headerlink" href="#swisstext.cmd.scraping.config.Config.interfaces_package" title="Permalink to this definition">¶</a></dt>
<dd><p>Should return the complete package where the interfaces are defined, if any.
In case this is defined and a tool is missing from the list, we will try to instantiate
the interface instead.</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.config.Config.tool_entry_name">
<code class="descname">tool_entry_name</code><a class="headerlink" href="#swisstext.cmd.scraping.config.Config.tool_entry_name" title="Permalink to this definition">¶</a></dt>
<dd><p>Should return the name of the tool_entries option, i.e. the YAML path to the dictionary of
[interface name, canonical class to instantiate].</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.config.Config.valid_tool_entries">
<code class="descname">valid_tool_entries</code><a class="headerlink" href="#swisstext.cmd.scraping.config.Config.valid_tool_entries" title="Permalink to this definition">¶</a></dt>
<dd><p>Should return the list of valid tool entries under the <a class="reference internal" href="#swisstext.cmd.scraping.config.Config.tool_entry_name" title="swisstext.cmd.scraping.config.Config.tool_entry_name"><code class="xref py py-attr docutils literal notranslate"><span class="pre">tool_entry_name</span></code></a>.
Note that the order of tools in the list defines the order of tools instances returned by
<code class="xref py py-meth docutils literal notranslate"><span class="pre">instantiate_tools()</span></code>.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-swisstext.cmd.scraping.data">
<span id="pipeline-implementation"></span><h2>Pipeline implementation<a class="headerlink" href="#module-swisstext.cmd.scraping.data" title="Permalink to this headline">¶</a></h2>
<p>This module defines the generic data structures used across the module / between the different tools.
They have been thought to be decoupled from MongoDB for better flexibility/adaptability.</p>
<dl class="class">
<dt id="swisstext.cmd.scraping.data.Page">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.data.</code><code class="descname">Page</code><span class="sig-paren">(</span><em>url</em>, <em>score=None</em>, <em>parent_url=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/data.html#Page"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.data.Page" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Information about a page.
Some attributes should be defined upon creation (see <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ISaver.get_page" title="swisstext.cmd.scraping.interfaces.ISaver.get_page"><code class="xref py py-meth docutils literal notranslate"><span class="pre">swisstext.cmd.scraping.interfaces.ISaver.get_page()</span></code></a>),
will other will be added/used incrementally by the different tools of the pipeline.</p>
<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Page.blacklisted">
<code class="descname">blacklisted</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Page.blacklisted" title="Permalink to this definition">¶</a></dt>
<dd><p>is the URL blacklisted ?</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Page.crawl_results">
<code class="descname">crawl_results</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Page.crawl_results" title="Permalink to this definition">¶</a></dt>
<dd><p>results of the crawl (see <code class="xref py py-class docutils literal notranslate"><span class="pre">ICrawler</span></code>)</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.data.Page.is_new">
<code class="descname">is_new</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/data.html#Page.is_new"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.data.Page.is_new" title="Permalink to this definition">¶</a></dt>
<dd><p>Test if the page is new or not, based on the <code class="xref py py-attr docutils literal notranslate"><span class="pre">delta_date</span></code>.</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Page.new_sg">
<code class="descname">new_sg</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Page.new_sg" title="Permalink to this definition">¶</a></dt>
<dd><p>new sentences found</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Page.parent_url">
<code class="descname">parent_url</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Page.parent_url" title="Permalink to this definition">¶</a></dt>
<dd><p>the parent URL, if the crawl depth is &gt; 1</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Page.score">
<code class="descname">score</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Page.score" title="Permalink to this definition">¶</a></dt>
<dd><p>page score</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Page.sentence_count">
<code class="descname">sentence_count</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Page.sentence_count" title="Permalink to this definition">¶</a></dt>
<dd><p>total number of sentences on the page</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Page.sg_count">
<code class="descname">sg_count</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Page.sg_count" title="Permalink to this definition">¶</a></dt>
<dd><p>number of Swiss German sentences on the page, wether they are new or not</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Page.url">
<code class="descname">url</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Page.url" title="Permalink to this definition">¶</a></dt>
<dd><p>the URL of the page</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.data.PageScore">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.data.</code><code class="descname">PageScore</code><span class="sig-paren">(</span><em>count=0</em>, <em>delta_count=0</em>, <em>delta_date=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/data.html#PageScore"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.data.PageScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Scoring information for a page used, among other things, to decide if a URL should be crawled or not.</p>
<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.PageScore.count">
<code class="descname">count</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.PageScore.count" title="Permalink to this definition">¶</a></dt>
<dd><p>total number of new sentences found on this page (for all the visits)</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.PageScore.delta_count">
<code class="descname">delta_count</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.PageScore.delta_count" title="Permalink to this definition">¶</a></dt>
<dd><p>number of new sentences found on this page in the last visit</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.PageScore.delta_date">
<code class="descname">delta_date</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.PageScore.delta_date" title="Permalink to this definition">¶</a></dt>
<dd><p>date of the last visit (in UTC) or None if never visited</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.data.Sentence">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.data.</code><code class="descname">Sentence</code><span class="sig-paren">(</span><em>text: str</em>, <em>proba: float</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/data.html#Sentence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.data.Sentence" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Information about a sentence.</p>
<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Sentence.proba">
<code class="descname">proba</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Sentence.proba" title="Permalink to this definition">¶</a></dt>
<dd><p>the Swiss German probability</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.data.Sentence.text">
<code class="descname">text</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.data.Sentence.text" title="Permalink to this definition">¶</a></dt>
<dd><p>the exact text</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-swisstext.cmd.scraping.page_queue"></span><dl class="class">
<dt id="swisstext.cmd.scraping.page_queue.PageQueue">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.page_queue.</code><code class="descname">PageQueue</code><span class="sig-paren">(</span><em>maxsize=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/page_queue.html#PageQueue"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.page_queue.PageQueue" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/queue.html#queue.Queue" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">queue.Queue</span></code></a></p>
<p>A <a class="reference external" href="https://docs.python.org/3/library/queue.html#queue.Queue" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Queue</span></code></a> that ensures enqueued pages are unique and not clearly pointing to images or PDFs
(i.e. ending with .jpg, .jpeg, .png or .pdf).</p>
<p>Elements in the queue should be <strong>tuples</strong>, with the first element a <code class="xref py py-class docutils literal notranslate"><span class="pre">Page</span></code> and the second the
crawl depth (as int)</p>
</dd></dl>

<span class="target" id="module-swisstext.cmd.scraping.pipeline"></span><p>This module contains the core of the scraping system.</p>
<p>In order to be fully customizable, it uses the concept of interfaces heavily: most of the decisions and steps
are delegated to instances of classes defined in <a class="reference internal" href="#module-swisstext.cmd.scraping.interfaces" title="swisstext.cmd.scraping.interfaces"><code class="xref py py-mod docutils literal notranslate"><span class="pre">interfaces</span></code></a>.</p>
<p>Here is an example usage.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">swisstext.cmd.scraping.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">PipelineWorker</span>
<span class="kn">from</span> <span class="nn">swisstext.cmd.scraping.data</span> <span class="kn">import</span> <span class="n">Page</span>
<span class="kn">from</span> <span class="nn">swisstext.cmd.scraping.page_queue</span> <span class="kn">import</span> <span class="n">PageQueue</span>
<span class="kn">from</span> <span class="nn">swisstext.cmd.scraping.config</span> <span class="kn">import</span> <span class="n">Config</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="c1"># print some information to the console</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;swisstext&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>

<span class="n">queue</span><span class="p">:</span> <span class="n">PageQueue</span> <span class="o">=</span> <span class="n">PageQueue</span><span class="p">()</span>
<span class="n">new_sentences</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># load the config and create the default pipeline</span>
<span class="c1"># WARNING: the default config will try to connect to MongoDB on localhost:27017</span>
<span class="c1"># if you don&#39;t want to use Mongo, create a config file and use the ConsoleSaver instead</span>
<span class="c1"># or use the hack: pipeline.saver = ConsoleSaver()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">Config</span><span class="p">(</span><span class="n">config_path</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span> <span class="c1"># set the config path if you have one</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">create_pipeline</span><span class="p">()</span>

<span class="c1"># add one page to the queue</span>
<span class="n">start_url</span> <span class="o">=</span> <span class="s1">&#39;http://www.hunold.ch/zw/goeteborg.html&#39;</span>
<span class="n">queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">Page</span><span class="p">(</span><span class="n">start_url</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># add the tuple (url, depth) with a depth of 1</span>

<span class="c1"># launch one worker</span>
<span class="n">worker</span> <span class="o">=</span> <span class="n">PipelineWorker</span><span class="p">()</span>
<span class="n">worker</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">new_sentences</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">crawl_depth</span><span class="p">)</span>
</pre></div>
</div>
<dl class="class">
<dt id="swisstext.cmd.scraping.pipeline.Pipeline">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.pipeline.</code><code class="descname">Pipeline</code><span class="sig-paren">(</span><em>crawler: swisstext.cmd.scraping.interfaces.ICrawler</em>, <em>splitter: swisstext.cmd.scraping.interfaces.ISplitter</em>, <em>filter: swisstext.cmd.scraping.interfaces.ISentenceFilter</em>, <em>detector: swisstext.cmd.scraping.interfaces.ISgDetector</em>, <em>seeder: swisstext.cmd.scraping.interfaces.ISeedCreator</em>, <em>decider: swisstext.cmd.scraping.interfaces.IDecider</em>, <em>saver: swisstext.cmd.scraping.interfaces.ISaver</em>, <em>min_proba=0.85</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/pipeline.html#Pipeline"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.pipeline.Pipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Holds instances of all needed interfaces and variables.</p>
<p>Note that pipelines are meant to be instantiated by a <a class="reference internal" href="#swisstext.cmd.scraping.config.Config" title="swisstext.cmd.scraping.config.Config"><code class="xref py py-class docutils literal notranslate"><span class="pre">Config</span></code></a> object,
not manually.</p>
</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.pipeline.PipelineWorker">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.pipeline.</code><code class="descname">PipelineWorker</code><span class="sig-paren">(</span><em>id=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/pipeline.html#PipelineWorker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.pipeline.PipelineWorker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Pipeline workers actually do the magic and can be run in parallel.</p>
<dl class="attribute">
<dt id="swisstext.cmd.scraping.pipeline.PipelineWorker.id">
<code class="descname">id</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.pipeline.PipelineWorker.id" title="Permalink to this definition">¶</a></dt>
<dd><p>an identifier used in log messages, especially useful if multiple threads are used.</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.pipeline.PipelineWorker.kill_received">
<code class="descname">kill_received</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.pipeline.PipelineWorker.kill_received" title="Permalink to this definition">¶</a></dt>
<dd><p>If the worker is launched in a thread, you can use this flag to make it exit prematurely.
Workers will always finish processing the current page before exiting, so that we can ensure
coherence in the persistence layer.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.pipeline.PipelineWorker.run">
<code class="descname">run</code><span class="sig-paren">(</span><em>queue: queue.Queue, p: swisstext.cmd.scraping.pipeline.Pipeline, new_sentences: List[str], max_depth=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/pipeline.html#PipelineWorker.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.pipeline.PipelineWorker.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Do the work ! All the magic is in here :)</p>
<p>For each page pulled from the queue, the worker will execute all the steps of the scraping pipeline:</p>
<ul class="simple">
<li>get text and links,</li>
<li>split and filter sentences,</li>
<li>keep sentences with Swiss German,</li>
<li>persist the results (url + sentences), if any</li>
<li>add new tasks to the queue (if the page contains links to interesting URLs)</li>
</ul>
<p>New sentences are added to the new_sentences list, so that the caller can easily know how fruitful the
scraping was and optionaly use the new sentences to generate seeds.</p>
<p>This method will stop:</p>
<ul class="simple">
<li>when the queue is empty or</li>
<li>if the <a class="reference internal" href="#swisstext.cmd.scraping.pipeline.PipelineWorker.kill_received" title="swisstext.cmd.scraping.pipeline.PipelineWorker.kill_received"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kill_received</span></code></a> is set to true. In this case, it finishes processing the current task and exit</li>
</ul>
<div class="admonition-todo admonition" id="index-1">
<p class="first admonition-title">Todo</p>
<p>This piece of code (and the commandline) has many flaws and should clearly be enhanced… For example:</p>
<p><strong>Multithreading</strong>: currently, the worker stops when the queue is empty. This also means that if
you launch the system with only 3 base urls but 5 workers, 2 workers will exit immediately instead
of waiting for new tasks to be added to the queue.</p>
<p>A better way would be to keep track of active workers and stop only when all workers are idle, or
when all workers reached a task with a depth &gt; max depth…</p>
<p class="last"><strong>Comportement on errors</strong>: in case fetching the URL triggers an error, we currently just log the thing.
Should we also remove/blacklist the URL ? Should we allow the URL to fail X times before removal ?</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>queue</strong> – the task queue</li>
<li><strong>p</strong> – the pipeline to use</li>
<li><strong>new_sentences</strong> – all new sentences discovered will be added to this list</li>
<li><strong>max_depth</strong> – when do we stop (inclusive)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Scraping commandline tool</a><ul>
<li><a class="reference internal" href="#usage">Usage</a></li>
<li><a class="reference internal" href="#module-swisstext.cmd.scraping.interfaces">Tool interfaces</a></li>
<li><a class="reference internal" href="#tool-implementations">Tool implementations</a></li>
<li><a class="reference internal" href="#module-swisstext.cmd.scraping.config">Configuration</a></li>
<li><a class="reference internal" href="#module-swisstext.cmd.scraping.data">Pipeline implementation</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="swisstext.mongo.abstract.html"
                        title="previous chapter">MongoDB Collections definitions</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="swisstext.cmd.scraping.tools.html"
                        title="next chapter">Command line scraping tools</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/swisstext.cmd.scraping.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="swisstext.cmd.scraping.tools.html" title="Command line scraping tools"
             >next</a> |</li>
        <li class="right" >
          <a href="swisstext.mongo.abstract.html" title="MongoDB Collections definitions"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">SwissText  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="apireference.html" >API Reference</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Lucy Linder.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.6.
    </div>
  </body>
</html>