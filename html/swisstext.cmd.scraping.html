
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Scraping commandline tool &#8212; SwissText  documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Command line scraping tools" href="swisstext.cmd.scraping.tools.html" />
    <link rel="prev" title="Commandline tools" href="swisstext.cmd.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="swisstext.cmd.scraping.tools.html" title="Command line scraping tools"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="swisstext.cmd.html" title="Commandline tools"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">SwissText  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="apireference.html" >API Reference</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="swisstext.cmd.html" accesskey="U">Commandline tools</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-swisstext.cmd.scraping">
<span id="scraping-commandline-tool"></span><h1>Scraping commandline tool<a class="headerlink" href="#module-swisstext.cmd.scraping" title="Permalink to this headline">¶</a></h1>
<p>The scraping module is able to scrape the web in order to find new Swiss German sentences.</p>
<div class="section" id="st-scrape">
<h2>st_scrape<a class="headerlink" href="#st-scrape" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>st_scrape <span class="o">[</span>OPTIONS<span class="o">]</span> COMMAND <span class="o">[</span>ARGS<span class="o">]</span>...
</pre></div>
</div>
<p class="rubric">Options</p>
<dl class="option">
<dt id="cmdoption-st-scrape-l">
<code class="descname">-l</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--log-level</code><code class="descclassname"> &lt;log_level&gt;</code><a class="headerlink" href="#cmdoption-st-scrape-l" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="option">
<dt id="cmdoption-st-scrape-c">
<code class="descname">-c</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--config-path</code><code class="descclassname"> &lt;config_path&gt;</code><a class="headerlink" href="#cmdoption-st-scrape-c" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="option">
<dt id="cmdoption-st-scrape-d">
<code class="descname">-d</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--db</code><code class="descclassname"> &lt;db&gt;</code><a class="headerlink" href="#cmdoption-st-scrape-d" title="Permalink to this definition">¶</a></dt>
<dd><p>If set, this will override the database set in the config</p>
</dd></dl>

<div class="section" id="st-scrape-dump-config">
<h3>dump_config<a class="headerlink" href="#st-scrape-dump-config" title="Permalink to this headline">¶</a></h3>
<p>Prints the active configuration. If &lt;test&gt; is set, the pipeline is also instantiated,
ensuring all tool names exist and use correct options.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>st_scrape dump_config <span class="o">[</span>OPTIONS<span class="o">]</span>
</pre></div>
</div>
<p class="rubric">Options</p>
<dl class="option">
<dt id="cmdoption-st-scrape-dump-config-t">
<code class="descname">-t</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--test</code><code class="descclassname"></code><a class="headerlink" href="#cmdoption-st-scrape-dump-config-t" title="Permalink to this definition">¶</a></dt>
<dd><p>Also instantiate the tools</p>
</dd></dl>

</div>
<div class="section" id="st-scrape-from-file">
<h3>from_file<a class="headerlink" href="#st-scrape-from-file" title="Permalink to this headline">¶</a></h3>
<p>Scrape using URLs in a file as base.</p>
<p>This script runs the scraping pipeline using the URLs present in a file as bootstrap URLs.
The file should have one URL per line. Any line starting with something other that “http” will be ignored.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>st_scrape from_file <span class="o">[</span>OPTIONS<span class="o">]</span> URLFILE
</pre></div>
</div>
<p class="rubric">Arguments</p>
<dl class="option">
<dt id="cmdoption-st-scrape-from-file-arg-urlfile">
<code class="descname">URLFILE</code><code class="descclassname"></code><a class="headerlink" href="#cmdoption-st-scrape-from-file-arg-urlfile" title="Permalink to this definition">¶</a></dt>
<dd><p>Required argument</p>
</dd></dl>

</div>
<div class="section" id="st-scrape-from-mongo">
<h3>from_mongo<a class="headerlink" href="#st-scrape-from-mongo" title="Permalink to this headline">¶</a></h3>
<p>Scrape using mongo URLs as base.</p>
<p>This script runs the scraping pipeline using -n bootstrap URLs pulled from Mongo. Those URLs are
selected depending on the number of visits and the date of the last visit (less visited first, oldest visit first).
If –new is specified, only URLs that have never been visited will be used (so the number of bootstrap URLs
actually used might be less than -n, if not enough new URLs are present).
If –any is specified, exactly -n URLs are selected (except if -n is less than the total number of URLs in the
collection).</p>
<p>Note that to connect to MongoDB, it relies on the host, port and db options present in the <cite>saver_options</cite> property
of the configuration. So whatever saver you use, ensure that those properties are correct
(default: localhost:27017, db=swisstext).</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>st_scrape from_mongo <span class="o">[</span>OPTIONS<span class="o">]</span>
</pre></div>
</div>
<p class="rubric">Options</p>
<dl class="option">
<dt id="cmdoption-st-scrape-from-mongo-n">
<code class="descname">-n</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--num-urls</code><code class="descclassname"> &lt;num_urls&gt;</code><a class="headerlink" href="#cmdoption-st-scrape-from-mongo-n" title="Permalink to this definition">¶</a></dt>
<dd><p>Max URLs crawled in one pass.</p>
</dd></dl>

<dl class="option">
<dt id="cmdoption-st-scrape-from-mongo-new">
<code class="descname">--new</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--any</code><code class="descclassname"></code><a class="headerlink" href="#cmdoption-st-scrape-from-mongo-new" title="Permalink to this definition">¶</a></dt>
<dd><p>Only crawl new URLs</p>
</dd></dl>

</div>
<div class="section" id="st-scrape-gen-seeds">
<h3>gen_seeds<a class="headerlink" href="#st-scrape-gen-seeds" title="Permalink to this headline">¶</a></h3>
<p>Generate seeds from a sample of mongo sentences.</p>
<p>This script generates -n seeds using a given number of sentences (-s) pulled from MongoDB.
If –new is specified, the latest sentences are used (date_added).
If –any is specified, sentences are selected randomly.</p>
<p>Note that: (1) seeds will be saved to the persistence layer using the saver class specified in the configuration.
(2) to connect to MongoDB, it relies on the host, port and db options present in the <cite>saver_options</cite> property
of the configuration. So whatever saver you use, ensure that those properties are correct
(default: localhost:27017, db=swisstext).</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>st_scrape gen_seeds <span class="o">[</span>OPTIONS<span class="o">]</span>
</pre></div>
</div>
<p class="rubric">Options</p>
<dl class="option">
<dt id="cmdoption-st-scrape-gen-seeds-s">
<code class="descname">-s</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--num-sentences</code><code class="descclassname"> &lt;num_sentences&gt;</code><a class="headerlink" href="#cmdoption-st-scrape-gen-seeds-s" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of sentences to use.</p>
</dd></dl>

<dl class="option">
<dt id="cmdoption-st-scrape-gen-seeds-n">
<code class="descname">-n</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--num</code><code class="descclassname"> &lt;num&gt;</code><a class="headerlink" href="#cmdoption-st-scrape-gen-seeds-n" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of seeds to generate.</p>
</dd></dl>

<dl class="option">
<dt id="cmdoption-st-scrape-gen-seeds-new">
<code class="descname">--new</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--any</code><code class="descclassname"></code><a class="headerlink" href="#cmdoption-st-scrape-gen-seeds-new" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the newest sentences</p>
</dd></dl>

<dl class="option">
<dt id="cmdoption-st-scrape-gen-seeds-c">
<code class="descname">-c</code><code class="descclassname"></code><code class="descclassname">, </code><code class="descname">--confirm</code><code class="descclassname"></code><a class="headerlink" href="#cmdoption-st-scrape-gen-seeds-c" title="Permalink to this definition">¶</a></dt>
<dd><p>Ask for confirmation before saving.</p>
</dd></dl>

</div>
</div>
<div class="section" id="module-swisstext.cmd.scraping.interfaces">
<span id="tool-interfaces"></span><h2>Tool interfaces<a class="headerlink" href="#module-swisstext.cmd.scraping.interfaces" title="Permalink to this headline">¶</a></h2>
<p>This module defines interfaces for each tool or decision maker used in the scraping process.
This makes it easy to test new ways or to tune one aspect of the scraper while keeping most of the code unchanged.</p>
<p>See the <a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools" title="swisstext.cmd.scraping.tools"><code class="xref py py-mod docutils literal notranslate"><span class="pre">swisstext.cmd.scraping.tools</span></code></a> module for implementations.</p>
<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ICrawler</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ICrawler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>[ABSTRACT] This tool is in charge of crawling a page. More specifically, it should be able to:
1. extract the text of the page (stripped of any HTML or other structural clue),
2. extract links pointing to other pages</p>
<dl class="exception">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.CrawlError">
<em class="property">exception </em><code class="descname">CrawlError</code><span class="sig-paren">(</span><em>message: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ICrawler.CrawlError"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlError" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#Exception" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></a></p>
<p>This wrapper should be used for any exception that arise during scraping.</p>
</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults">
<em class="property">class </em><code class="descname">CrawlResults</code><span class="sig-paren">(</span><em>text: str, links: List[str]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ICrawler.CrawlResults"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Holds the results of a page crawl.</p>
<dl class="attribute">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults.links">
<code class="descname">links</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults.links" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of interesting links found in the page. By interesting, we mean:
* no duplicates
* different from the current page URL (no anchors !)
* if possible, no link pointing to unparseable resources (zip files, images, etc.)
The method <a class="reference internal" href="swisstext.cmd.html#swisstext.cmd.link_utils.filter_links" title="swisstext.cmd.link_utils.filter_links"><code class="xref py py-meth docutils literal notranslate"><span class="pre">swisstext.cmd.link_utils.filter_links()</span></code></a> is available to do the filtering.</p>
</dd></dl>

<dl class="attribute">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults.text">
<code class="descname">text</code><em class="property"> = None</em><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults.text" title="Permalink to this definition">¶</a></dt>
<dd><p>the clean text found in the page, free of any structural marker such as HTML tags, etc.</p>
</dd></dl>

</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ICrawler.crawl">
<code class="descname">crawl</code><span class="sig-paren">(</span><em>url: str</em><span class="sig-paren">)</span> &#x2192; swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ICrawler.crawl"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ICrawler.crawl" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT]
Should crawl the page and extract the text and the links into a <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults" title="swisstext.cmd.scraping.interfaces.ICrawler.CrawlResults"><code class="xref py py-class docutils literal notranslate"><span class="pre">ICrawler.CrawlResults</span></code></a> instance.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.IDecider">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">IDecider</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#IDecider"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.IDecider" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A decider should implement the logic behind whether or not a URL is considered interesting/should be crawled.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.IDecider.should_children_be_crawled">
<code class="descname">should_children_be_crawled</code><span class="sig-paren">(</span><em>page: swisstext.cmd.scraping.data.Page</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#IDecider.should_children_be_crawled"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.IDecider.should_children_be_crawled" title="Permalink to this definition">¶</a></dt>
<dd><p>Decide if the links found on a page should be scraped on this run. Returns true by default.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.IDecider.should_page_be_crawled">
<code class="descname">should_page_be_crawled</code><span class="sig-paren">(</span><em>page: swisstext.cmd.scraping.data.Page</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#IDecider.should_page_be_crawled"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.IDecider.should_page_be_crawled" title="Permalink to this definition">¶</a></dt>
<dd><p>Decide if a page should be scraped on this run. By default, it returns always true, but we could devise other
rules based on the last crawl, etc.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.IDecider.should_url_be_blacklisted">
<code class="descname">should_url_be_blacklisted</code><span class="sig-paren">(</span><em>page: swisstext.cmd.scraping.data.Page</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#IDecider.should_url_be_blacklisted"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.IDecider.should_url_be_blacklisted" title="Permalink to this definition">¶</a></dt>
<dd><p>Decide if a URL/page is blacklisted. The default implementation returns true if the URL has never been
visited before <em>and</em> contains no Swiss German sentence. The <em>new</em> criteria is important to avoid blacklisting
a page that changed over time, but contained once interesting sentences (and thus might be referenced in
the persistence layer).</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISaver">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISaver</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>[ABSTRACT] The saver is responsible for persisting everything somewhere, such as a database, a file or the console.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.blacklist_url">
<code class="descname">blacklist_url</code><span class="sig-paren">(</span><em>url: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.blacklist_url"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.blacklist_url" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Add the <cite>url</cite> to a blacklist.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.get_page">
<code class="descname">get_page</code><span class="sig-paren">(</span><em>url: str</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.get_page"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.get_page" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a page. The simplest implementation is just <code class="docutils literal notranslate"><span class="pre">return</span> <span class="pre">Page(url)</span></code>.
If the subclass uses a data store, it should also populate the other page attributes (e.g. the score
information) so that the :py:class::<cite>IDecider</cite> can make clever decisions.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.is_url_blacklisted">
<code class="descname">is_url_blacklisted</code><span class="sig-paren">(</span><em>url: str</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.is_url_blacklisted"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.is_url_blacklisted" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Tells if the given <cite>url</cite> is part of the blacklist. This is called at the beginning,
to avoid scraping pages unnecessarily.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.save_page">
<code class="descname">save_page</code><span class="sig-paren">(</span><em>page: swisstext.cmd.scraping.data.Page</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.save_page"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.save_page" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Persist a page.
This is called after the scraping, so all page’s attributes are set, including the
list of new :py:class::<cite>~swisstext.cmd.scraping.data.Sentence</cite> found.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.save_seed">
<code class="descname">save_seed</code><span class="sig-paren">(</span><em>seed: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.save_seed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.save_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Persist a seed (usually generated by the :py:class::<cite>ISeedGenerator</cite>).</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.save_seeds">
<code class="descname">save_seeds</code><span class="sig-paren">(</span><em>seeds: List[str]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.save_seeds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.save_seeds" title="Permalink to this definition">¶</a></dt>
<dd><p>Persist multiple seeds (see <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ISaver.save_seed" title="swisstext.cmd.scraping.interfaces.ISaver.save_seed"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_seed()</span></code></a>).</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISaver.sentence_exists">
<code class="descname">sentence_exists</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISaver.sentence_exists"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISaver.sentence_exists" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Tells if the given Swiss German <cite>sentence</cite> already exists.
Only new sentences will be added to the page’s <a class="reference internal" href="swisstext.cmd.scraping.impl.html#swisstext.cmd.scraping.data.Page.new_sg" title="swisstext.cmd.scraping.data.Page.new_sg"><code class="xref py py-attr docutils literal notranslate"><span class="pre">new_sg</span></code></a> attribute.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISeedCreator">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISeedCreator</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISeedCreator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISeedCreator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>[ABSTRACT] A seed creator should generate seeds, i.e. search queries, out of Swiss German sentences.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISeedCreator.generate_seeds">
<code class="descname">generate_seeds</code><span class="sig-paren">(</span><em>sentences: List[str], max=10, stopwords: List[str] = []</em><span class="sig-paren">)</span> &#x2192; List[str]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISeedCreator.generate_seeds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISeedCreator.generate_seeds" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Should generate interesting seeds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sentences</strong> – the sentences</p></li>
<li><p><strong>max</strong> – maximum number of seeds to return</p></li>
<li><p><strong>stopwords</strong> – an optional list of words to exclude from generated seeds</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list of seeds</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISentenceFilter">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISentenceFilter</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISentenceFilter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISentenceFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A sentence filter should be able to tell if a given sentence is well-formed (i.e. valid) or not.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISentenceFilter.filter">
<code class="descname">filter</code><span class="sig-paren">(</span><em>sentences: List[str]</em><span class="sig-paren">)</span> &#x2192; List[str]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISentenceFilter.filter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISentenceFilter.filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter a list of sentences by calling <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ISentenceFilter.is_valid" title="swisstext.cmd.scraping.interfaces.ISentenceFilter.is_valid"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ISentenceFilter.is_valid()</span></code></a> on each element.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISentenceFilter.is_valid">
<code class="descname">is_valid</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISentenceFilter.is_valid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISentenceFilter.is_valid" title="Permalink to this definition">¶</a></dt>
<dd><p>This should be overriden. The default implementation just returns true.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISgDetector">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISgDetector</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISgDetector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISgDetector" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>[ABSTRACT] An SG Detector is a Language Identifier supporting Swiss German.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISgDetector.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>sentences: List[str]</em><span class="sig-paren">)</span> &#x2192; List[float]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISgDetector.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISgDetector.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>[ABSTRACT] Predict the Swiss German probability (between 0 and 1) of a list of sentences.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISgDetector.predict_one">
<code class="descname">predict_one</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISgDetector.predict_one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISgDetector.predict_one" title="Permalink to this definition">¶</a></dt>
<dd><p>Call <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ISgDetector.predict" title="swisstext.cmd.scraping.interfaces.ISgDetector.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> with one sentence.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="swisstext.cmd.scraping.interfaces.ISplitter">
<em class="property">class </em><code class="descclassname">swisstext.cmd.scraping.interfaces.</code><code class="descname">ISplitter</code><a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISplitter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISplitter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A splitter should take a [long] text (extracted from a web page) and split it into well-formed sentences.
The default implementation just splits on the newline character.</p>
<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISplitter.split">
<code class="descname">split</code><span class="sig-paren">(</span><em>text: str</em><span class="sig-paren">)</span> &#x2192; List[str]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISplitter.split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISplitter.split" title="Permalink to this definition">¶</a></dt>
<dd><p>This should be overriden. The default implementation just splits on newlines.</p>
</dd></dl>

<dl class="method">
<dt id="swisstext.cmd.scraping.interfaces.ISplitter.split_all">
<code class="descname">split_all</code><span class="sig-paren">(</span><em>texts: List[str]</em><span class="sig-paren">)</span> &#x2192; List[str]<a class="reference internal" href="_modules/swisstext/cmd/scraping/interfaces.html#ISplitter.split_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#swisstext.cmd.scraping.interfaces.ISplitter.split_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a list of texts and returns a list of sentences (see <a class="reference internal" href="#swisstext.cmd.scraping.interfaces.ISplitter.split" title="swisstext.cmd.scraping.interfaces.ISplitter.split"><code class="xref py py-meth docutils literal notranslate"><span class="pre">split()</span></code></a>).</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="tool-implementations">
<h2>Tool implementations<a class="headerlink" href="#tool-implementations" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="swisstext.cmd.scraping.tools.html">Command line scraping tools</a><ul>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.basic_decider">Deciders</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.basic_seed_creator">Seed Creators</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.bs_crawler">Crawlers</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.console_saver">Savers</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.pattern_sentence_filter">Sentence Filters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#how-it-works">How it works</a></li>
<li class="toctree-l3"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#rule-syntax">Rule syntax</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.punkt_splitter">Splitters</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.tools.html#module-swisstext.cmd.scraping.tools.swigspot_langid">Language Detectors</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="pipeline-implementation">
<h2>Pipeline implementation<a class="headerlink" href="#pipeline-implementation" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="swisstext.cmd.scraping.impl.html">Pipeline implementation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.impl.html#module-swisstext.cmd.scraping.config">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.impl.html#module-swisstext.cmd.scraping.data">Data structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.impl.html#module-swisstext.cmd.scraping.page_queue">Queue</a></li>
<li class="toctree-l2"><a class="reference internal" href="swisstext.cmd.scraping.impl.html#module-swisstext.cmd.scraping.pipeline">Pipeline</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Scraping commandline tool</a><ul>
<li><a class="reference internal" href="#st-scrape">st_scrape</a><ul>
<li><a class="reference internal" href="#st-scrape-dump-config">dump_config</a></li>
<li><a class="reference internal" href="#st-scrape-from-file">from_file</a></li>
<li><a class="reference internal" href="#st-scrape-from-mongo">from_mongo</a></li>
<li><a class="reference internal" href="#st-scrape-gen-seeds">gen_seeds</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-swisstext.cmd.scraping.interfaces">Tool interfaces</a></li>
<li><a class="reference internal" href="#tool-implementations">Tool implementations</a></li>
<li><a class="reference internal" href="#pipeline-implementation">Pipeline implementation</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="swisstext.cmd.html"
                        title="previous chapter">Commandline tools</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="swisstext.cmd.scraping.tools.html"
                        title="next chapter">Command line scraping tools</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/swisstext.cmd.scraping.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="swisstext.cmd.scraping.tools.html" title="Command line scraping tools"
             >next</a> |</li>
        <li class="right" >
          <a href="swisstext.cmd.html" title="Commandline tools"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">SwissText  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="apireference.html" >API Reference</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="swisstext.cmd.html" >Commandline tools</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Lucy Linder.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.0.1.
    </div>
  </body>
</html>